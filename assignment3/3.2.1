from scipy.io import loadmat
from sklearn import model_selection, tree
import treeprint
import numpy as np
import matplotlib.pyplot as plt

# Load Matlab data file and extract variables of interest
wine_data = loadmat('Data/wine.mat')
X = wine_data['X']
y = wine_data['y'].ravel()

attributeNames = [array[0] for array in wine_data['attributeNames'].ravel()]
classNames = [array[0] for array in wine_data['classNames'].ravel()]

# Simple holdout-set crossvalidation
X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)

#write your code here
dtc = tree.DecisionTreeClassifier(min_samples_split=100)    #create tree
dtc = dtc.fit(X_train,y_train)     #fit on data
#treeprint.tree_print(dtc, attributeNames, classNames)


train_errors = []
test_errors = []
for i in range(2,20):
    classifier = tree.DecisionTreeClassifier(max_depth = i)
    train_error = 1-model_selection.cross_val_score(classifier, X_train, y_train)
    train_errors.append(train_error.mean())
    test_error = 1-model_selection.cross_val_score(classifier, X_test, y_test)
    test_errors.append(test_error.mean())

train_errors = np.array(train_errors)
test_errors = np.array(test_errors)

plt.plot(range(2,20), train_errors)
plt.plot(range(2,20), test_errors)
plt.xlabel('max depth')
plt.ylabel('error')
plt.title('classification error')
plt.legend(['trainset', 'testset'], loc='upper right')
plt.show()
