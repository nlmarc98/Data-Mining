from scipy.io import loadmat
from sklearn import model_selection, tree
import treeprint
import numpy as np
import matplotlib.pyplot as pl
K = 100
kf = model_selection.KFold(n_splits=K)

train_errors = [[] for i in range(10)]
test_errors = [[] for i in range(10)]
split = 0
for train, test in kf.split(X):
    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]
    dtc = tree.DecisionTreeClassifier(min_samples_split=100)    #create tree
    dtc = dtc.fit(X_train,y_train)     #fit on data
    
    for i in range(2,20):
        classifier = tree.DecisionTreeClassifier(max_depth = i)
        train_error = 1-model_selection.cross_val_score(classifier, X_train, y_train)
        train_errors[split].append(train_error.mean())
        test_error = 1-model_selection.cross_val_score(classifier, X_test, y_test)
        test_errors[split].append(test_error.mean())
    split = split + 1
       
train_errors = np.array(train_errors)
test_errors = np.array(test_errors)


plt.plot(range(2,20), train_errors.mean(0))
plt.plot(range(2,20), test_errors.mean(0))
plt.xlabel('max depth')
plt.ylabel('error')
plt.title('classification error')
plt.legend(['trainset', 'testset'], loc='upper right')
plt.show()
